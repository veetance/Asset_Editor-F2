.\venv\Scripts\python.exe : 
W0119 05:34:06.441000 20936 venv
\Lib\site-packages\torch\distrib
uted\elastic\multiprocessing\red
irects.py:29] NOTE: Redirects 
are currently not supported in 
Windows or MacOs.
At line:1 char:1
+ .\venv\Scripts\python.exe 
test_pipeline.py > test_log.txt 
2>&1
+ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    + CategoryInfo          : N 
   otSpecified: (W0119 05:34:0  
  6....ndows or MacOs.:String   
 ) [], RemoteException
    + FullyQualifiedErrorId : N 
   ativeCommandError
 
`torch_dtype` is deprecated! 
Use `dtype` instead!
[LOADER] Initiating FLUX.2-klein-4B pipeline...
[LOADER] Manual Assembly: Loading Components...

Loading checkpoint shards:   
0%|          | 0/2 [00:00<?, 
?it/s]
Loading checkpoint shards: 
100%|##########| 2/2 
[00:00<00:00, 49.31it/s]
Traceback (most recent call 
last):
  File "E:\Data-D-2\FLUX-2-KLEIN
\test_pipeline.py", line 49, in 
<module>
    print(f"Transformer 
processor: 
{pipe.transformer.processor}")
                                
    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Data-D-2\FLUX-2-KLEIN
\venv\Lib\site-packages\diffuser
s\models\modeling_utils.py", 
line 274, in __getattr__
    return 
super().__getattr__(name)
           
^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Data-D-2\FLUX-2-KLEIN
\venv\Lib\site-packages\torch\nn
\modules\module.py", line 1964, 
in __getattr__
    raise AttributeError(
AttributeError: 
'Flux2Transformer2DModel' 
object has no attribute 
'processor'
Guidance scale 4.0 is ignored 
for step-wise distilled models.
[LOADER] Pipeline Assembled: Flux2KleinPipeline {
  "_class_name": "Flux2KleinPipeline",
  "_diffusers_version": "0.37.0.dev0",
  "is_distilled": true,
  "scheduler": [
    "diffusers",
    "FlowMatchEulerDiscreteScheduler"
  ],
  "text_encoder": [
    "transformers",
    "Qwen3ForCausalLM"
  ],
  "tokenizer": [
    "transformers",
    "Qwen2TokenizerFast"
  ],
  "transformer": [
    "diffusers",
    "Flux2Transformer2DModel"
  ],
  "vae": [
    "diffusers",
    "AutoencoderKLFlux2"
  ]
}


[LOADER] Engaging Native SDPA (Stable Engine)...
[LOADER] Locking Manifold to GPU (Locked)...
[LOADER] FLUX.2-klein-4B Pipeline Ready.

--- DEEP DIAGNOSTICS ---
Pipeline: Flux2KleinPipeline {
  "_class_name": "Flux2KleinPipeline",
  "_diffusers_version": "0.37.0.dev0",
  "is_distilled": true,
  "scheduler": [
    "diffusers",
    "FlowMatchEulerDiscreteScheduler"
  ],
  "text_encoder": [
    "transformers",
    "Qwen3ForCausalLM"
  ],
  "tokenizer": [
    "transformers",
    "Qwen2TokenizerFast"
  ],
  "transformer": [
    "diffusers",
    "Flux2Transformer2DModel"
  ],
  "vae": [
    "diffusers",
    "AutoencoderKLFlux2"
  ]
}

Transformer: Flux2Transformer2DModel(
  (pos_embed): Flux2PosEmbed()
  (time_guidance_embed): Flux2TimestepGuidanceEmbeddings(
    (time_proj): Timesteps()
    (timestep_embedder): TimestepEmbedding(
      (linear_1): Linear(in_features=256, out_features=3072, bias=False)
      (act): SiLU()
      (linear_2): Linear(in_features=3072, out_features=3072, bias=False)
    )
  )
  (double_stream_modulation_img): Flux2Modulation(
    (linear): Linear(in_features=3072, out_features=18432, bias=False)
    (act_fn): SiLU()
  )
  (double_stream_modulation_txt): Flux2Modulation(
    (linear): Linear(in_features=3072, out_features=18432, bias=False)
    (act_fn): SiLU()
  )
  (single_stream_modulation): Flux2Modulation(
    (linear): Linear(in_features=3072, out_features=9216, bias=False)
    (act_fn): SiLU()
  )
  (x_embedder): Linear(in_features=128, out_features=3072, bias=False)
  (context_embedder): Linear(in_features=7680, out_features=3072, bias=False)
  (transformer_blocks): ModuleList(
    (0-4): 5 x Flux2TransformerBlock(
      (norm1): LayerNorm((3072,), eps=1e-06, elementwise_affine=False)
      (norm1_context): LayerNorm((3072,), eps=1e-06, elementwise_affine=False)
      (attn): Flux2Attention(
        (to_q): Linear(in_features=3072, out_features=3072, bias=False)
        (to_k): Linear(in_features=3072, out_features=3072, bias=False)
        (to_v): Linear(in_features=3072, out_features=3072, bias=False)
        (norm_q): RMSNorm((128,), eps=1e-06, elementwise_affine=True)
        (norm_k): RMSNorm((128,), eps=1e-06, elementwise_affine=True)
        (to_out): ModuleList(
          (0): Linear(in_features=3072, out_features=3072, bias=False)
          (1): Dropout(p=0.0, inplace=False)
        )
        (norm_added_q): RMSNorm((128,), eps=1e-06, elementwise_affine=True)
        (norm_added_k): RMSNorm((128,), eps=1e-06, elementwise_affine=True)
        (add_q_proj): Linear(in_features=3072, out_features=3072, bias=False)
        (add_k_proj): Linear(in_features=3072, out_features=3072, bias=False)
        (add_v_proj): Linear(in_features=3072, out_features=3072, bias=False)
        (to_add_out): Linear(in_features=3072, out_features=3072, bias=False)
      )
      (norm2): LayerNorm((3072,), eps=1e-06, elementwise_affine=False)
      (ff): Flux2FeedForward(
        (linear_in): Linear(in_features=3072, out_features=18432, bias=False)
        (act_fn): Flux2SwiGLU(
          (gate_fn): SiLU()
        )
        (linear_out): Linear(in_features=9216, out_features=3072, bias=False)
      )
      (norm2_context): LayerNorm((3072,), eps=1e-06, elementwise_affine=False)
      (ff_context): Flux2FeedForward(
        (linear_in): Linear(in_features=3072, out_features=18432, bias=False)
        (act_fn): Flux2SwiGLU(
          (gate_fn): SiLU()
        )
        (linear_out): Linear(in_features=9216, out_features=3072, bias=False)
      )
    )
  )
  (single_transformer_blocks): ModuleList(
    (0-19): 20 x Flux2SingleTransformerBlock(
      (norm): LayerNorm((3072,), eps=1e-06, elementwise_affine=False)
      (attn): Flux2ParallelSelfAttention(
        (to_qkv_mlp_proj): Linear(in_features=3072, out_features=27648, bias=False)
        (mlp_act_fn): Flux2SwiGLU(
          (gate_fn): SiLU()
        )
        (norm_q): RMSNorm((128,), eps=1e-06, elementwise_affine=True)
        (norm_k): RMSNorm((128,), eps=1e-06, elementwise_affine=True)
        (to_out): Linear(in_features=12288, out_features=3072, bias=False)
      )
    )
  )
  (norm_out): AdaLayerNormContinuous(
    (silu): SiLU()
    (linear): Linear(in_features=3072, out_features=6144, bias=False)
    (norm): LayerNorm((3072,), eps=1e-06, elementwise_affine=False)
  )
  (proj_out): Linear(in_features=3072, out_features=128, bias=False)
)
Scheduler: FlowMatchEulerDiscreteScheduler {
  "_class_name": "FlowMatchEulerDiscreteScheduler",
  "_diffusers_version": "0.37.0.dev0",
  "base_image_seq_len": 256,
  "base_shift": 0.5,
  "invert_sigmas": false,
  "max_image_seq_len": 4096,
  "max_shift": 1.15,
  "num_train_timesteps": 1000,
  "shift": 3.0,
  "shift_terminal": null,
  "stochastic_sampling": false,
  "time_shift_type": "exponential",
  "use_beta_sigmas": false,
  "use_dynamic_shifting": true,
  "use_exponential_sigmas": false,
  "use_karras_sigmas": false
}

Attribute 'vae': <class 'diffusers.models.autoencoders.autoencoder_kl_flux2.AutoencoderKLFlux2'> - OK
Attribute 'text_encoder': <class 'transformers.models.qwen3.modeling_qwen3.Qwen3ForCausalLM'> - OK
Attribute 'tokenizer': <class 'transformers.models.qwen2.tokenization_qwen2_fast.Qwen2TokenizerFast'> - OK
Attribute 'transformer': <class 'diffusers.models.transformers.transformer_flux2.Flux2Transformer2DModel'> - OK
Attribute 'scheduler': <class 'diffusers.schedulers.scheduling_flow_match_euler_discrete.FlowMatchEulerDiscreteScheduler'> - OK
Attribute 'image_processor': <class 'diffusers.pipelines.flux2.image_processor.Flux2ImageProcessor'> - OK
Does transformer have 'cache_context': True
Scheduler has 'config': True
Scheduler has 'order': True
Scheduler has 'set_begin_index': True
Transformer forward signature: (hidden_states: torch.Tensor, encoder_hidden_states: torch.Tensor = None, timestep: torch.LongTensor = None, img_ids: torch.Tensor = None, txt_ids: torch.Tensor = None, guidance: torch.Tensor = None, joint_attention_kwargs: Optional[Dict[str, Any]] = None, return_dict: bool = True) -> Union[torch.Tensor, diffusers.models.modeling_outputs.Transformer2DModelOutput]

--- STARTING GENERATION TEST ---
Step 1: Encoding prompt...
Step 2: Preparing latents...
Step 3: Running one transformer step manually...
Attempting manual transformer call...
Manual transformer call FAILED: 'Flux2Transformer2DModel' object has no attribute 'processor'

Attempting full pipe call...
  0%|          | 0/1 [00:00<?, 
?it/s]
  0%|          | 0/1 [00:00<?, 
?it/s]
Traceback (most recent call 
last):
  File "E:\Data-D-2\FLUX-2-KLEIN
\test_pipeline.py", line 76, in 
<module>
    result = pipe(
             ^^^^^
  File "E:\Data-D-2\FLUX-2-KLEIN
\venv\Lib\site-packages\torch\ut
ils\_contextlib.py", line 120, 
in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Data-D-2\FLUX-2-KLEIN
\venv\Lib\site-packages\diffuser
s\pipelines\flux2\pipeline_flux2
_klein.py", line 843, in 
__call__
    noise_pred = 
self.transformer(
                 
^^^^^^^^^^^^^^^^^
  File "E:\Data-D-2\FLUX-2-KLEIN
\venv\Lib\site-packages\torch\nn
\modules\module.py", line 1775, 
in _wrapped_call_impl
    return 
self._call_impl(*args, **kwargs)
           
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Data-D-2\FLUX-2-KLEIN
\venv\Lib\site-packages\torch\nn
\modules\module.py", line 1786, 
in _call_impl
    return forward_call(*args, 
**kwargs)
           
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Data-D-2\FLUX-2-KLEIN
\venv\Lib\site-packages\diffuser
s\models\transformers\transforme
r_flux2.py", line 874, in 
forward
    encoder_hidden_states, 
hidden_states = block(
                                
           ^^^^^^
  File "E:\Data-D-2\FLUX-2-KLEIN
\venv\Lib\site-packages\torch\nn
\modules\module.py", line 1775, 
in _wrapped_call_impl
    return 
self._call_impl(*args, **kwargs)
           
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Data-D-2\FLUX-2-KLEIN
\venv\Lib\site-packages\torch\nn
\modules\module.py", line 1786, 
in _call_impl
    return forward_call(*args, 
**kwargs)
           
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Data-D-2\FLUX-2-KLEIN
\venv\Lib\site-packages\diffuser
s\models\transformers\transforme
r_flux2.py", line 521, in 
forward
    attention_outputs = 
self.attn(
                        
^^^^^^^^^^
  File "E:\Data-D-2\FLUX-2-KLEIN
\venv\Lib\site-packages\torch\nn
\modules\module.py", line 1775, 
in _wrapped_call_impl
    return 
self._call_impl(*args, **kwargs)
           
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Data-D-2\FLUX-2-KLEIN
\venv\Lib\site-packages\torch\nn
\modules\module.py", line 1786, 
in _call_impl
    return forward_call(*args, 
**kwargs)
           
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Data-D-2\FLUX-2-KLEIN
\venv\Lib\site-packages\diffuser
s\models\transformers\transforme
r_flux2.py", line 249, in 
forward
    attn_parameters = set(inspec
t.signature(self.processor.__cal
l__).parameters.keys())
                                
            
^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' 
object has no attribute 
'__call__'. Did you mean: 
'__bool__'?

FULL PIPE ERROR: 'NoneType' object has no attribute '__call__'
